{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/Ro2aTJjRfpFS0uoIMATl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ghadgeabhi/Langchain/blob/main/langchain_data_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install chromadb\n",
        "!pip install faiss-cpu\n",
        "!pip install unstructured\n",
        "!pip install deeplake\n",
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgwi-u-nPn9e",
        "outputId": "af78abd8-9d8f-48d4-df42-063db6ea4786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.9/dist-packages (0.0.134)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.4.47)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.9/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.9/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.9/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.9/dist-packages (from langchain) (2.28.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.9/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.9/dist-packages (0.27.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.28.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (1.8.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (22.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.9/dist-packages (0.3.21)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.10.7)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.5.20)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.9/dist-packages (from chromadb) (2.4.2)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from chromadb) (2.2.2)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.95.0)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.7.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.9/dist-packages (from chromadb) (2.28.2)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.4.4)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /usr/local/lib/python3.9/dist-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.9/dist-packages (from chromadb) (1.22.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (1.26.15)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (0.20.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.7.1)\n",
            "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /usr/local/lib/python3.9/dist-packages (from fastapi>=0.85.1->chromadb) (0.26.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.9/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.9->chromadb) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->chromadb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.28->chromadb) (3.4)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (4.27.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.15.1+cu118)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.1.97)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from sentence-transformers>=2.2.2->chromadb) (4.65.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (6.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.9/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers>=2.2.2->chromadb) (3.10.7)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.11.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (3.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->sentence-transformers>=2.2.2->chromadb) (8.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/dist-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.6.0->sentence-transformers>=2.2.2->chromadb) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.9/dist-packages (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unstructured in /usr/local/lib/python3.9/dist-packages (0.5.11)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.9/dist-packages (from unstructured) (0.8.11)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from unstructured) (8.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from unstructured) (4.9.2)\n",
            "Requirement already satisfied: pypandoc in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.11)\n",
            "Requirement already satisfied: msg-parser in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from unstructured) (2.28.2)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.9/dist-packages (from unstructured) (0.4.27)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.4.3)\n",
            "Requirement already satisfied: python-pptx in /usr/local/lib/python3.9/dist-packages (from unstructured) (0.6.21)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.9/dist-packages (from unstructured) (2022.12.7)\n",
            "Requirement already satisfied: argilla in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.5.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.0.10)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from unstructured) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from unstructured) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (23.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.13 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.24.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.22.4)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (2.2.1)\n",
            "Requirement already satisfied: rich<=13.0.1 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (13.0.1)\n",
            "Requirement already satisfied: pydantic>=1.7.1 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.10.7)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.6)\n",
            "Requirement already satisfied: deprecated~=1.2.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (1.2.13)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (4.65.0)\n",
            "Requirement already satisfied: httpx<0.24,>=0.15 in /usr/local/lib/python3.9/dist-packages (from argilla->unstructured) (0.23.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->unstructured) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->unstructured) (2022.7.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown->unstructured) (6.1.0)\n",
            "Requirement already satisfied: olefile>=0.46 in /usr/local/lib/python3.9/dist-packages (from msg-parser->unstructured) (0.46)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (1.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk->unstructured) (8.1.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.9/dist-packages (from openpyxl->unstructured) (1.1.0)\n",
            "Requirement already satisfied: XlsxWriter>=0.5.7 in /usr/local/lib/python3.9/dist-packages (from python-pptx->unstructured) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->unstructured) (2.0.12)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.5.0)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (0.16.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/dist-packages (from httpx<0.24,>=0.15->argilla->unstructured) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown->unstructured) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic>=1.7.1->argilla->unstructured) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->unstructured) (1.16.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich<=13.0.1->argilla->unstructured) (2.14.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.9/dist-packages (from rich<=13.0.1->argilla->unstructured) (0.9.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (3.6.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.9/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx<0.24,>=0.15->argilla->unstructured) (0.14.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deeplake in /usr/local/lib/python3.9/dist-packages (3.2.21)\n",
            "Requirement already satisfied: numcodecs in /usr/local/lib/python3.9/dist-packages (from deeplake) (0.11.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from deeplake) (8.1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from deeplake) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from deeplake) (1.22.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.9/dist-packages (from deeplake) (1.24.59)\n",
            "Requirement already satisfied: aioboto3==10.4.0 in /usr/local/lib/python3.9/dist-packages (from deeplake) (10.4.0)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/dist-packages (from deeplake) (1.5.6)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.9/dist-packages (from deeplake) (0.3.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from deeplake) (8.4.0)\n",
            "Requirement already satisfied: humbug>=0.2.6 in /usr/local/lib/python3.9/dist-packages (from deeplake) (0.3.1)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.9/dist-packages (from deeplake) (2.6.0)\n",
            "Requirement already satisfied: aiobotocore[boto3]==2.4.2 in /usr/local/lib/python3.9/dist-packages (from aioboto3==10.4.0->deeplake) (2.4.2)\n",
            "Requirement already satisfied: wrapt>=1.10.10 in /usr/local/lib/python3.9/dist-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.14.1)\n",
            "Requirement already satisfied: aiohttp>=3.3.1 in /usr/local/lib/python3.9/dist-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (3.8.4)\n",
            "Requirement already satisfied: aioitertools>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (0.11.0)\n",
            "Requirement already satisfied: botocore<1.27.60,>=1.27.59 in /usr/local/lib/python3.9/dist-packages (from aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.27.59)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from boto3->deeplake) (0.6.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.9/dist-packages (from boto3->deeplake) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from humbug>=0.2.6->deeplake) (2.28.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.9/dist-packages (from numcodecs->deeplake) (0.4)\n",
            "Requirement already satisfied: pox>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from pathos->deeplake) (0.3.2)\n",
            "Requirement already satisfied: multiprocess>=0.70.14 in /usr/local/lib/python3.9/dist-packages (from pathos->deeplake) (0.70.14)\n",
            "Requirement already satisfied: ppft>=1.7.6.6 in /usr/local/lib/python3.9/dist-packages (from pathos->deeplake) (1.7.6.6)\n",
            "Requirement already satisfied: dill>=0.3.6 in /usr/local/lib/python3.9/dist-packages (from pathos->deeplake) (0.3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.9/dist-packages (from botocore<1.27.60,>=1.27.59->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.9/dist-packages (from botocore<1.27.60,>=1.27.59->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->humbug>=0.2.6->deeplake) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->humbug>=0.2.6->deeplake) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->humbug>=0.2.6->deeplake) (3.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (22.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp>=3.3.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (6.0.4)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.9/dist-packages (from aioitertools>=0.5.1->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (4.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.60,>=1.27.59->aiobotocore[boto3]==2.4.2->aioboto3==10.4.0->deeplake) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2.28.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken) (2022.10.31)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_f6hWLBM_B4",
        "outputId": "f7a5ae55-1f49-4b0a-91e0-894b41ca9cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (2.28.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "I8O8UPXpmEh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using random data"
      ],
      "metadata": {
        "id": "wqevEDSBnrIi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUGdiqGDPU_o",
        "outputId": "9a838e21-1338-416f-fd0d-a3053185f6af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "urls = [\n",
        "    \"https://www.understandingwar.org/backgrounder/russian-offensive-campaign-assessment-february-8-2023\",\n",
        "    \"https://www.understandingwar.org/backgrounder/russian-offensive-campaign-assessment-february-9-2023\"\n",
        "]\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "data = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Index\n",
        "import tiktoken\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "\n",
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4HsmyJcl8R2",
        "outputId": "c062704a-456c-4ee9-a349-fc300afd54a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the key takeaways from this piece\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "nq9JejS4mWoI",
        "outputId": "9dd628c5-cd94-4bd7-f2a7-36eab973e286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The key takeaways from this piece are that GPT is moving from a technology to try out into a real-life use case-based technology, and that GPT can be trained for task-based operations. Additionally, it is suggested that GPT can be used to help with large lawsuits by quickly and accurately analyzing the text.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"can you elaborate in about 500 words on the key takeaways\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Wu5_O9s1mwi1",
        "outputId": "5bd62df2-60b9-43cd-ca55-6fa0c298df32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nThe key takeaway from the GPT evolution is that it is becoming increasingly specialized and task-based. This means that it is no longer just a technology to try out, but is now being used in real-life use cases. This is made possible by the deep learning protocols that GPT is based on, which allow it to learn from different contexts.\\n\\nThe OpenAI library has made it possible for anyone to use GPT, regardless of their technical knowledge. This library is available in NodeJS and Python, and it allows users to fine-tune their models based on their data and use case. This means that GPT can be trained on specific text documents, such as law suits files, code documentation, and high school English textbooks.\\n\\nThe potential of GPT is immense. It can be used to create a parallelized consciousness, where a blog with hundreds of posts can be brought to life by asking questions to it. It can also be used to help with legal cases, where a large lawsuit can be uploaded as input and questions can be asked to get relevant output.\\n\\nOverall, GPT is becoming increasingly specialized and task-based, and it is now available to anyone who wants to use it. It can be used to create'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"how would you summarie this piece\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "WLhnLQ6ynhaL",
        "outputId": "1015cfb4-9224-494a-8ee8-125355ad61bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This piece explains how GPT can be used to help with specific tasks, such as analyzing a lawsuit. It explains how GPT can be trained on specific text documents and how GPT 3.4 and GPT 4 both have this feature. It also provides a link to OpenAI to learn more.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using darticle data"
      ],
      "metadata": {
        "id": "k8yqy_D3n3oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "urls = [\n",
        "    \"https://www.darticle.io/article/aws-a-security-group-primer\"\n",
        "]\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "U2PTO6vqn8Zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Index\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "\n",
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOjVg8Jtrpx4",
        "outputId": "f26a580f-08ed-41a3-be91-0671da6c03ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the key takeaways from this piece\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "mLvjRFWOrtqi",
        "outputId": "777ed25e-50c2-4f10-8c31-7f7c5ad6ab96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The key takeaways from this piece are that GPT is moving from a technology to try out into a real-life use case-based technology, and that GPT can be trained for task-based operations. Additionally, it is suggested that GPT can be used to help with large lawsuits by quickly reading and understanding the text.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the main topics of his aticles?\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pXmsA5lQsBIB",
        "outputId": "8820f241-7fa5-4fb6-c131-3728724710aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Abhishek Ghadge's articles mainly focus on Decentralization, Artificial Intelligence, and GPT (Generative Pre-trained Transformer) technology.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What can you tell me about the author?\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eszanQRksWGq",
        "outputId": "5ab17c07-7ac8-4f38-cb21-6eeccb1f4114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The author is Abhishek Ghadge. He is an avid traveller and a big fan of the beach. He is the creator of dArticle, a decentralized blogging application. He has a 0x9579DAab31... address and 6 followers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using darticle data"
      ],
      "metadata": {
        "id": "N_6iJk-9vs3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "urls = [\n",
        "    \"https://www.darticle.io/article/the-next-step-in-the-gpt-evolution\"\n",
        "]\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "data = loader.load()"
      ],
      "metadata": {
        "id": "a-rdICqLvqj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Index\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "\n",
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66U0NCBJvwy_",
        "outputId": "72c08c22-ffe6-4190-a793-4af3a2eb2579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the key takeaways from this piece\"\n",
        "index.query(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "vb_oPjm-v0hK",
        "outputId": "0bf24c4e-86d3-43e9-bb20-340c7ad9b727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The key takeaways from this piece are that GPT is moving from a technology to try out into a real-life use case-based technology, and that GPT can be trained for task-based operations. Additionally, it is suggested that GPT can be used to help with large lawsuits by quickly and accurately analyzing the text.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Persisting embeddings\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9KajL2yDNR7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import DeepLake\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "uaqnGB5P4QRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logging into activeloop\n",
        "!activeloop login -t eyJhbGciOiJIUzUxMiIsImlhdCI6MTY4MDgwNTU5NSwiZXhwIjoxNzEyNDI3OTU5fQ.eyJpZCI6InJhaHVseWFsbWF0In0.7aGdHnTOkTYwucICF_qa2QHg49Bqgn5ryA5cMb-Rpqr9WADly9hSXCUkYi4sfc4zrLUg5KW0QOKmKbwduFeqDg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_7XDNTr5_t5",
        "outputId": "d7ecda4d-7331-48b3-8b87-da9e52742899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully logged in to Activeloop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "urls = [\n",
        "    \"https://www.darticle.io/article/the-next-step-in-the-gpt-evolution\"\n",
        "]\n",
        "loader = UnstructuredURLLoader(urls=urls)\n",
        "data = loader.load()\n",
        "\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBIs9Sl81zv9",
        "outputId": "98ec8850-bf6c-406e-c4db-a51e87840acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Created a chunk of size 2506, which is longer than the specified 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Index\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "\n",
        "index = VectorstoreIndexCreator().from_loaders([loader])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmU_W5_n19HY",
        "outputId": "40ffc735-fce7-4c5c-ae9f-fae0fd4a9701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = DeepLake.from_documents(docs, embeddings)\n",
        "\n",
        "query = \"Can you summarize this article\"\n",
        "parts = db.similarity_search(query)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8IjVu9G2ABL",
        "outputId": "0f1c7b4c-e031-4006-997a-43f9c6c9b17c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mem://langchain loaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating ingest: 0%|          | 0/7 [00:00<?"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating ingest: 100%|██████████| 7/7 [00:04<00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(), chain_type=\"stuff\", retriever=retriever)\n",
        "query = \"Can you summarize this article\"\n",
        "\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "wu2lNN8JCPGc",
        "outputId": "54209d1d-3ebf-4be7-8e05-06d1e9d66b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This article discusses the evolution of GPT (Generative Pre-trained Transformer) from a technology to try out to becoming a real-life use case-based technology. The author encourages readers to use dArticle, a decentralized blogging application, to utilize this technology with specific models for their specific cases. The author provides updates on decentralization and artificial intelligence concepts.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(parts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKg0UtCA7V6s",
        "outputId": "317e0bbe-9afd-4f95-8108-22cf27a0c41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='dArticle, a decentralized blogging application, currently has this feature, so be sure to use it as your publishing platform!\\n\\nFollow me for more updates on Decentralization and Artificial Intelligence concepts.\\n\\nYou are  viewing an NFT\\n\\nRarible\\n\\nOpensea\\n\\nPolygon\\n\\nComments\\n\\n0 comments\\n\\nAbout the Author\\n\\nAbhishek Ghadge\\n\\n0x9579DAab...\\n\\nAvid Traveller | Big fan of the beach\\n\\nTrending', metadata={'source': 'https://www.darticle.io/article/the-next-step-in-the-gpt-evolution'}), Document(page_content='dArticle.io\\n\\nWrite\\n\\nHow it works\\n\\ndArticle.io\\n\\nAbhishek Ghadge\\n\\n0x9579DAab31...\\n\\n6 Followers\\n\\nAvid Traveller | Big fan of the beach\\n\\n+Follow\\n\\nHow it works\\n\\nCommunity\\n\\nBlog\\n\\nAbout\\n\\nTerms of Service\\n\\nPrivacy\\n\\nAbhishek Ghadge  Mar 24 2023     |     3 min read\\n\\nThe next step in the GPT evolution\\n\\nIt is going to bring life to your published work!\\n\\nChat GPT has taken over the world by storm, and it is moving from a technology to try out into a real-life use case-based technology. However, it is currently too general, and many people are not able to harness its power. More amount of people requires it to be used in their specific cases, with their specific models.', metadata={'source': 'https://www.darticle.io/article/the-next-step-in-the-gpt-evolution'}), Document(page_content='This is the next task of GPT, getting more specialized. With generality, development is easy as there is only a single general that fits the world. But when specificity is a deal-breaking requirement, the environment of the task plays a huge role. The environment or the area of specificity changes with each topic and simply cannot be transferred or moved around.\\n\\nAs GPT is based on deep learning protocols, it can learn from different contexts pretty easily. And this is where the next step in GPT lies. Training GPT for task-based operations.\\n\\nThe lawsuit use case\\n\\nSay you have a large lawsuit filed against you today. And that lawsuit is over 100 pages long of just text. You can spend half your life reading it or better use state-of-the-art technology to help your case. You can get 100 different lawyers provided you are rich to each individually review it and then explain it to you.', metadata={'source': 'https://www.darticle.io/article/the-next-step-in-the-gpt-evolution'}), Document(page_content='How it works\\n\\nCommunity\\n\\nBlog\\n\\nAbout\\n\\nTerms of Service\\n\\nPrivacy', metadata={'source': 'https://www.darticle.io/article/the-next-step-in-the-gpt-evolution'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed and store the texts\n",
        "dataset_path = \"hub://rahulyalmat/article_embeddings\" # could be also ./local/path (much faster locally), s3://bucket/path/to/dataset, gcs://, etc.\n",
        "\n",
        "embedding = OpenAIEmbeddings()\n",
        "vectordb = DeepLake.from_documents(documents=docs, embedding=embedding, dataset_path=dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLgyv4E55llz",
        "outputId": "6e143289-635e-40d1-a21f-8f36a0991865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/rahulyalmat/article_embeddings\n",
            "\n",
            "hub://rahulyalmat/article_embeddings loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Deep Lake Dataset in hub://rahulyalmat/article_embeddings already exists, loading from the storage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r \rDataset(path='hub://rahulyalmat/article_embeddings', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype     shape      dtype  compression\n",
            "  -------   -------   -------    -------  ------- \n",
            " embedding  generic  (11, 1536)   None     None   \n",
            "    ids      text     (11, 1)      str     None   \n",
            " metadata    json     (11, 1)      str     None   \n",
            "   text      text     (11, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ingest: 100%|██████████| 7/7 [00:00<00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEvaluating ingest: 100%|██████████| 7/7 [00:13<00:00"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r \r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.ds.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR3cyED85oXU",
        "outputId": "aec2edf2-930e-4660-b542-9dc621a446f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset(path='hub://rahulyalmat/article_embeddings', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype     shape      dtype  compression\n",
            "  -------   -------   -------    -------  ------- \n",
            " embedding  generic  (18, 1536)   None     None   \n",
            "    ids      text     (18, 1)      str     None   \n",
            " metadata    json     (18, 1)      str     None   \n",
            "   text      text     (18, 1)      str     None   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#loading data from Deeplake\n"
      ],
      "metadata": {
        "id": "7rLktkXg_4WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import deeplake \n",
        "from langchain.llms import OpenAIChat\n",
        "# ds = deeplake.load('hub://rahulyalmat/article_embeddings')\n",
        "# db = DeepLake.as_retriever(ds)\n",
        "# print(ds)\n",
        "db = DeepLake(dataset_path=\"hub://rahulyalmat/article_embeddings\", embedding_function=embeddings)\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAIChat(model='gpt-3.5-turbo'), chain_type='stuff', retriever=db.as_retriever())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKW3Xuqh_7zh",
        "outputId": "dd03949c-4473-4b59-8f06-b3dfb7bf6fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\rThis dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/rahulyalmat/article_embeddings\n",
            "\n",
            "hub://rahulyalmat/article_embeddings loaded successfully.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Deep Lake Dataset in hub://rahulyalmat/article_embeddings already exists, loading from the storage\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\rDataset(path='hub://rahulyalmat/article_embeddings', tensors=['embedding', 'ids', 'metadata', 'text'])\n",
            "\n",
            "  tensor     htype     shape      dtype  compression\n",
            "  -------   -------   -------    -------  ------- \n",
            " embedding  generic  (18, 1536)   None     None   \n",
            "    ids      text     (18, 1)      str     None   \n",
            " metadata    json     (18, 1)      str     None   \n",
            "   text      text     (18, 1)      str     None   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/langchain/llms/openai.py:623: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Can you summarize this article\"\n",
        "\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "4f02u-Jh-8-5",
        "outputId": "2103b5d1-a65c-4d60-fa2b-fcee1f0d9b0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The article discusses the use of Chat GPT technology in a decentralized blogging application called dArticle. The author suggests that while Chat GPT has become popular, it is currently too general and needs to be used in specific cases with specific models. The author recommends dArticle as a platform for publishing works using Chat GPT. The article also provides information about the author and displays an NFT viewing feature.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}